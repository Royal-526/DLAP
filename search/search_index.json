{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to DLAP \u00b6 \u5173\u4e8e\u6211\u4eec \u00b6 \u672c\u7f51\u7ad9\u662f\u4e3a\u4e86\u6df1\u5ea6\u5b66\u4e60\u4e0e\u7f16\u7a0b\u5b9e\u8df5\u8bad\u7ec3\u8425\u4e4b\u4f7f\u7528\uff0c\u7f51\u7ad9\u8bb0\u8f7d\u4e86\u6709\u5173\u7f16\u7a0b\u4e0e\u6df1\u5ea6\u5b66\u4e60\u7684\u5165\u95e8\u8d44\u6e90\u3002\u6bcf\u5468\u4e94\u3001\u516d\u3001\u65e5\u665a20\u65f6\u6211\u4eec\u4f1a\u5b9a\u671f\u5206\u4eab\u7279\u5b9a\u7684\u90e8\u5206\uff0c\u53ef\u4ee5\u70b9\u51fb\u5de6\u4fa7\u7684\u8fde\u63a5\u67e5\u770b\u5bf9\u5e94\u5404\u4e2a\u90e8\u5206\u7684\u5185\u5bb9\u6574\u7406\u3002 \u65f6\u95f4\u5b89\u6392 \u00b6 \u65f6\u95f4 \u5185\u5bb9 \u89c6\u9891 2020/6/12 MLP, CNN, Activation Function, Anaconda Usage, VSCode Intro, Intermediate Python Lang, PyTorch Intro video1 video2 2020/6/13 More about PyTorch Usage (Dataset, DataLoader, torchvision) 1 , Train a Classifier from Scratch, How to represent multi-modal data in NN? 2 2020/6/14 RNN(LSTM, GRU), Word2Vec, CVPR Paper Review: Deep Supervised Cross-Modal Retrieval video1 2020/6/19 CVPR Code Review: Deep Supervised Cross-Modal Retrieval; Seq2seq 2020/6/20 Attention, Pointer Network 2020/6/21 Seq2seq code review; ACL Paper Review: Fast Abstractive Summarization with Reinforce-Selected Sentence Rewriting 2020/6/26 Final Project 1: https://github.com/ChenRocks/fast_abs_rl 2020/6/27 Final Project 2: https://github.com/ChenRocks/fast_abs_rl 2020/6/28 Final Project 3: https://github.com/ChenRocks/fast_abs_rl https://pytorch.org/tutorials/beginner/data_loading_tutorial.html?highlight=dataloader \u21a9 Python\u6df1\u5ea6\u5b66\u4e60 \u21a9","title":"Welcome to DLAP"},{"location":"#welcome-to-dlap","text":"","title":"Welcome to DLAP"},{"location":"#_1","text":"\u672c\u7f51\u7ad9\u662f\u4e3a\u4e86\u6df1\u5ea6\u5b66\u4e60\u4e0e\u7f16\u7a0b\u5b9e\u8df5\u8bad\u7ec3\u8425\u4e4b\u4f7f\u7528\uff0c\u7f51\u7ad9\u8bb0\u8f7d\u4e86\u6709\u5173\u7f16\u7a0b\u4e0e\u6df1\u5ea6\u5b66\u4e60\u7684\u5165\u95e8\u8d44\u6e90\u3002\u6bcf\u5468\u4e94\u3001\u516d\u3001\u65e5\u665a20\u65f6\u6211\u4eec\u4f1a\u5b9a\u671f\u5206\u4eab\u7279\u5b9a\u7684\u90e8\u5206\uff0c\u53ef\u4ee5\u70b9\u51fb\u5de6\u4fa7\u7684\u8fde\u63a5\u67e5\u770b\u5bf9\u5e94\u5404\u4e2a\u90e8\u5206\u7684\u5185\u5bb9\u6574\u7406\u3002","title":"\u5173\u4e8e\u6211\u4eec"},{"location":"#_2","text":"\u65f6\u95f4 \u5185\u5bb9 \u89c6\u9891 2020/6/12 MLP, CNN, Activation Function, Anaconda Usage, VSCode Intro, Intermediate Python Lang, PyTorch Intro video1 video2 2020/6/13 More about PyTorch Usage (Dataset, DataLoader, torchvision) 1 , Train a Classifier from Scratch, How to represent multi-modal data in NN? 2 2020/6/14 RNN(LSTM, GRU), Word2Vec, CVPR Paper Review: Deep Supervised Cross-Modal Retrieval video1 2020/6/19 CVPR Code Review: Deep Supervised Cross-Modal Retrieval; Seq2seq 2020/6/20 Attention, Pointer Network 2020/6/21 Seq2seq code review; ACL Paper Review: Fast Abstractive Summarization with Reinforce-Selected Sentence Rewriting 2020/6/26 Final Project 1: https://github.com/ChenRocks/fast_abs_rl 2020/6/27 Final Project 2: https://github.com/ChenRocks/fast_abs_rl 2020/6/28 Final Project 3: https://github.com/ChenRocks/fast_abs_rl https://pytorch.org/tutorials/beginner/data_loading_tutorial.html?highlight=dataloader \u21a9 Python\u6df1\u5ea6\u5b66\u4e60 \u21a9","title":"\u65f6\u95f4\u5b89\u6392"},{"location":"1VSCode/","text":"VSCode and Python \u00b6 \u8d44\u6599\u6c47\u603b \u00b6 Python\u8fdb\u9636\u8bb2\u89e3 1 https://github.com/eastlakeside/interpy-zh/blob/master/SUMMARY.md \u21a9","title":"VSCode and Python"},{"location":"1VSCode/#vscode-and-python","text":"","title":"VSCode and Python"},{"location":"1VSCode/#_1","text":"Python\u8fdb\u9636\u8bb2\u89e3 1 https://github.com/eastlakeside/interpy-zh/blob/master/SUMMARY.md \u21a9","title":"\u8d44\u6599\u6c47\u603b"},{"location":"2PyTorch/","text":"PyTorch Intro \u00b6 \u8d44\u6599\u6c47\u603b \u00b6 \u5b9e\u8df5 \u00b6 \u53f0\u5927PyTorch\u76f8\u5173\u5165\u95e8slide 1 \u3001video 2 \uff1bPyTorch\u5b98\u65b9tutorial 3 \u7406\u8bba \u00b6 \u56de\u5f52\u95ee\u9898 4 \uff1b\u903b\u8f91\u65af\u8482\u56de\u5f52 5 \uff1b\u6df1\u5ea6\u5b66\u4e60\u5165\u95e8 6 \uff1b\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5 7 Tensor: \u4eceBatch\u8bf4\u8d77 \u00b6 \u4ee5Batch\u7684\u89d2\u5ea6\u770bMLP \u00b6 MLP\u505a\u56de\u5f52 \u00b6 MLP\u505a\u5206\u7c7b \u00b6 http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML2020/PyTorch_Introduction.slides.html#/ \u21a9 https://www.youtube.com/watch?v=kQeezFrNoOg&feature=youtu.be \u21a9 https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html \u21a9 https://www.bilibili.com/video/BV13x411v7US?p=3 \u21a9 https://www.bilibili.com/video/BV13x411v7US?p=11 \u21a9 https://www.bilibili.com/video/BV13x411v7US?p=13 \u21a9 https://www.bilibili.com/video/BV13x411v7US?p=14 \u21a9","title":"PyTorch Intro"},{"location":"2PyTorch/#pytorch-intro","text":"","title":"PyTorch Intro"},{"location":"2PyTorch/#_1","text":"","title":"\u8d44\u6599\u6c47\u603b"},{"location":"2PyTorch/#_2","text":"\u53f0\u5927PyTorch\u76f8\u5173\u5165\u95e8slide 1 \u3001video 2 \uff1bPyTorch\u5b98\u65b9tutorial 3","title":"\u5b9e\u8df5"},{"location":"2PyTorch/#_3","text":"\u56de\u5f52\u95ee\u9898 4 \uff1b\u903b\u8f91\u65af\u8482\u56de\u5f52 5 \uff1b\u6df1\u5ea6\u5b66\u4e60\u5165\u95e8 6 \uff1b\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5 7","title":"\u7406\u8bba"},{"location":"2PyTorch/#tensor-batch","text":"","title":"Tensor: \u4eceBatch\u8bf4\u8d77"},{"location":"2PyTorch/#batchmlp","text":"","title":"\u4ee5Batch\u7684\u89d2\u5ea6\u770bMLP"},{"location":"2PyTorch/#mlp","text":"","title":"MLP\u505a\u56de\u5f52"},{"location":"2PyTorch/#mlp_1","text":"http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML2020/PyTorch_Introduction.slides.html#/ \u21a9 https://www.youtube.com/watch?v=kQeezFrNoOg&feature=youtu.be \u21a9 https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html \u21a9 https://www.bilibili.com/video/BV13x411v7US?p=3 \u21a9 https://www.bilibili.com/video/BV13x411v7US?p=11 \u21a9 https://www.bilibili.com/video/BV13x411v7US?p=13 \u21a9 https://www.bilibili.com/video/BV13x411v7US?p=14 \u21a9","title":"MLP\u505a\u5206\u7c7b"},{"location":"3CNN/","text":"CNN \u00b6 \u8d44\u6599\u6c47\u603b \u00b6 CNN\u8bb2\u89e3slide 1 \u3001video 2 \u3001code 3 http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2017/Lecture/CNN.pdf \u21a9 https://www.bilibili.com/video/BV13x411v7US?p=21 \u21a9 https://colab.research.google.com/drive/16a3G7Hh8Pv1X1PhZAUBEnZEkXThzDeHJ \u21a9","title":"CNN"},{"location":"3CNN/#cnn","text":"","title":"CNN"},{"location":"3CNN/#_1","text":"CNN\u8bb2\u89e3slide 1 \u3001video 2 \u3001code 3 http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2017/Lecture/CNN.pdf \u21a9 https://www.bilibili.com/video/BV13x411v7US?p=21 \u21a9 https://colab.research.google.com/drive/16a3G7Hh8Pv1X1PhZAUBEnZEkXThzDeHJ \u21a9","title":"\u8d44\u6599\u6c47\u603b"},{"location":"4RNN/","text":"RNN \u00b6 \u8d44\u6599\u6c47\u603b \u00b6 RNN\u8bb2\u89e3slide 1 \u3001video 2 , 3 \u3001code 4 ; word2vec slide 5 \u3001video 6 \u3001 paper 7 http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2016/Lecture/RNN%20(v2).pdf \u21a9 https://www.bilibili.com/video/BV13x411v7US?p=36 \u21a9 https://www.bilibili.com/video/BV13x411v7US?p=37 \u21a9 https://colab.research.google.com/drive/16d1Xox0OW-VNuxDn1pvy2UXFIPfieCb9 \u21a9 http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2017/Lecture/word2vec%20(v2).pdf \u21a9 https://www.bilibili.com/video/BV13x411v7US?p=25 \u21a9 https://arxiv.org/pdf/1301.3781.pdf \u21a9","title":"RNN"},{"location":"4RNN/#rnn","text":"","title":"RNN"},{"location":"4RNN/#_1","text":"RNN\u8bb2\u89e3slide 1 \u3001video 2 , 3 \u3001code 4 ; word2vec slide 5 \u3001video 6 \u3001 paper 7 http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2016/Lecture/RNN%20(v2).pdf \u21a9 https://www.bilibili.com/video/BV13x411v7US?p=36 \u21a9 https://www.bilibili.com/video/BV13x411v7US?p=37 \u21a9 https://colab.research.google.com/drive/16d1Xox0OW-VNuxDn1pvy2UXFIPfieCb9 \u21a9 http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2017/Lecture/word2vec%20(v2).pdf \u21a9 https://www.bilibili.com/video/BV13x411v7US?p=25 \u21a9 https://arxiv.org/pdf/1301.3781.pdf \u21a9","title":"\u8d44\u6599\u6c47\u603b"},{"location":"5CVPR/","text":"CVPR: Cross-Modal Retrieval \u00b6 \u8d44\u6599\u6c47\u603b \u00b6 paper 1 , code 2 http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhen_Deep_Supervised_Cross-Modal_Retrieval_CVPR_2019_paper.pdf \u21a9 https://github.com/penghu-cs/DSCMR \u21a9","title":"CVPR: Cross-Modal Retrieval"},{"location":"5CVPR/#cvpr-cross-modal-retrieval","text":"","title":"CVPR: Cross-Modal Retrieval"},{"location":"5CVPR/#_1","text":"paper 1 , code 2 http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhen_Deep_Supervised_Cross-Modal_Retrieval_CVPR_2019_paper.pdf \u21a9 https://github.com/penghu-cs/DSCMR \u21a9","title":"\u8d44\u6599\u6c47\u603b"},{"location":"6Broadcast/","text":"Broadcast \u00b6 Exercises \u00b6 Calculate similarity matrix with 3 different methods cos, l1, and l2 Input ===== input_x: A Tensor with the shape in [batch_size, feature_size] method: A string indicates the similarity metric method, including cos, l1, and l2. Output ====== similarity_matrix: A Tensor with the shape in [batch_size, batch_size] Tip Try to use the broadcast mechanism instead of using for loop to implement it. For Loop \u5b9e\u73b0 \u00b6 \u4e3a\u4e86\u65b9\u4fbf\u7406\u89e3\u4efb\u52a1\u9700\u6c42\uff0c\u53ef\u4ee5\u9605\u8bfb\u57fa\u4e8e for \u5faa\u73af\u5b9e\u73b0\u7684\u4ee3\u7801\u3002 import torch def naive_pairwise_similarity ( input_x : torch . Tensor , method : str ) -> torch . Tensor : ''' Calculate similarity matrix with 3 different methods cos, l1, and l2. This is a naive implementation with for loop. Input ===== input_x: A Tensor with the shape in [batch_size, feature_size] method: A string indicate the similarity metric method Output ====== similarity_matrix: A Tensor with the shape in [batch_size, batch_size] ''' method_list = ( 'cos' , 'l1' , 'l2' ) if method not in method_list : raise ValueError ( \"only support method in {} \" . format ( method_list )) eps = 1e-23 batch_size = input_x . size ( 0 ) similarity_matrix = torch . zeros ( batch_size , batch_size ) for i in range ( batch_size ): for j in range ( batch_size ): if method == 'cos' : x = input_x [ i ] y = input_x [ j ] inner_product = ( x * y ) . sum () x_norm = x . square () . sum () . sqrt () y_norm = y . square () . sum () . sqrt () norm_product = x_norm * y_norm similarity_matrix [ i , j ] = inner_product / ( norm_product + eps ) elif method == 'l1' : sub = input_x [ i ] - input_x [ j ] similarity_matrix [ i , j ] = sub . abs () . sum () elif method == 'l2' : sub = input_x [ i ] - input_x [ j ] similarity_matrix [ i , j ] = sub . square () . sum () . sqrt () return similarity_matrix \u7ec3\u4e60\u6587\u4ef6 \u00b6 broadcast\u5f85\u5b9e\u73b0\u6587\u4ef6 , test script \u672c\u5730\u6d4b\u8bd5 \u00b6 \u5c06\u4e0b\u8f7d\u7684\u4e24\u4e2a\u6587\u4ef6\u7f6e\u4e8e\u540c\u4e00\u4e2a\u6587\u4ef6\u4e0b\uff0c\u5207\u6362\u5230\u6587\u4ef6\u6240\u5728\u76ee\u5f55\u4e0e\u6240\u9700\u7684python\u73af\u5883\u540e\uff0c\u5b8c\u6210 broadcast.py \u4e2d\u5bf9\u5e94\u7684\u51fd\u6570\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u76f4\u63a5\u8fd0\u884c python broadcast_test.py \u8fdb\u884c\u6d4b\u8bd5\uff0c\u8fd9\u4e2a\u811a\u672c\u4f1a\u6d4b\u8bd5\u8ba1\u7b97\u7ed3\u679c\u7684\u6b63\u786e\u6027\u4ee5\u53ca\u8017\u65f6\uff0c\u901a\u8fc7\u6d4b\u8bd5\u540e\u5f97\u5230\u7684\u7ed3\u679c\u5982\u56fe\u6240\u793a\uff1a \u53ef\u4ee5\u770b\u5230\u4f7f\u7528 for \u5b9e\u73b0\u7684\u51fd\u6570\u8fdc\u8fdc\u4e0d\u5982\u5e7f\u64ad\u673a\u5236\u6765\u7684\u9ad8\u6548\u3002 \u53ef\u80fd\u7684\u7b54\u6848 \u00b6 pairwise_similarity def pairwise_similarity ( input_x : torch . Tensor , method : str ) -> torch . Tensor : ''' Calculate similarity matrix with 3 different methods cos, l1, and l2 Input ===== input_x: A Tensor with the shape in [batch_size, feature_size] method: A string indicate the similarity metric method Output ====== similarity_matrix: A Tensor with the shape in [batch_size, batch_size] ''' method_list = ( 'cos' , 'l1' , 'l2' ) if method not in method_list : raise ValueError ( f 'only support method in { method_list } ' ) # TODO: Finish your code here batch_size = input_x . size ( 0 ) similarity_matrix = torch . zeros ( batch_size , batch_size ) if method == 'l1' : similarity_matrix = (( input_x . unsqueeze ( 0 ) - input_x . unsqueeze ( 1 )) . abs ()) . sum ( - 1 ) elif method == 'l2' : similarity_matrix = torch . sqrt ((( input_x . unsqueeze ( 0 ) - input_x . unsqueeze ( 2 )) ** 2 ) . sum ( - 1 )) elif method == 'cos' : similarity_matrix = ( input_x . unsqueeze ( 0 ) * input_x . unsqueeze ( 1 )) / ( input_x . unsqueeze ( 0 ) * input_x . unsqueeze ( 0 )) return similarity_matrix","title":"Broadcast"},{"location":"6Broadcast/#broadcast","text":"","title":"Broadcast"},{"location":"6Broadcast/#exercises","text":"Calculate similarity matrix with 3 different methods cos, l1, and l2 Input ===== input_x: A Tensor with the shape in [batch_size, feature_size] method: A string indicates the similarity metric method, including cos, l1, and l2. Output ====== similarity_matrix: A Tensor with the shape in [batch_size, batch_size] Tip Try to use the broadcast mechanism instead of using for loop to implement it.","title":"Exercises"},{"location":"6Broadcast/#for-loop","text":"\u4e3a\u4e86\u65b9\u4fbf\u7406\u89e3\u4efb\u52a1\u9700\u6c42\uff0c\u53ef\u4ee5\u9605\u8bfb\u57fa\u4e8e for \u5faa\u73af\u5b9e\u73b0\u7684\u4ee3\u7801\u3002 import torch def naive_pairwise_similarity ( input_x : torch . Tensor , method : str ) -> torch . Tensor : ''' Calculate similarity matrix with 3 different methods cos, l1, and l2. This is a naive implementation with for loop. Input ===== input_x: A Tensor with the shape in [batch_size, feature_size] method: A string indicate the similarity metric method Output ====== similarity_matrix: A Tensor with the shape in [batch_size, batch_size] ''' method_list = ( 'cos' , 'l1' , 'l2' ) if method not in method_list : raise ValueError ( \"only support method in {} \" . format ( method_list )) eps = 1e-23 batch_size = input_x . size ( 0 ) similarity_matrix = torch . zeros ( batch_size , batch_size ) for i in range ( batch_size ): for j in range ( batch_size ): if method == 'cos' : x = input_x [ i ] y = input_x [ j ] inner_product = ( x * y ) . sum () x_norm = x . square () . sum () . sqrt () y_norm = y . square () . sum () . sqrt () norm_product = x_norm * y_norm similarity_matrix [ i , j ] = inner_product / ( norm_product + eps ) elif method == 'l1' : sub = input_x [ i ] - input_x [ j ] similarity_matrix [ i , j ] = sub . abs () . sum () elif method == 'l2' : sub = input_x [ i ] - input_x [ j ] similarity_matrix [ i , j ] = sub . square () . sum () . sqrt () return similarity_matrix","title":"For Loop \u5b9e\u73b0"},{"location":"6Broadcast/#_1","text":"broadcast\u5f85\u5b9e\u73b0\u6587\u4ef6 , test script","title":"\u7ec3\u4e60\u6587\u4ef6"},{"location":"6Broadcast/#_2","text":"\u5c06\u4e0b\u8f7d\u7684\u4e24\u4e2a\u6587\u4ef6\u7f6e\u4e8e\u540c\u4e00\u4e2a\u6587\u4ef6\u4e0b\uff0c\u5207\u6362\u5230\u6587\u4ef6\u6240\u5728\u76ee\u5f55\u4e0e\u6240\u9700\u7684python\u73af\u5883\u540e\uff0c\u5b8c\u6210 broadcast.py \u4e2d\u5bf9\u5e94\u7684\u51fd\u6570\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u76f4\u63a5\u8fd0\u884c python broadcast_test.py \u8fdb\u884c\u6d4b\u8bd5\uff0c\u8fd9\u4e2a\u811a\u672c\u4f1a\u6d4b\u8bd5\u8ba1\u7b97\u7ed3\u679c\u7684\u6b63\u786e\u6027\u4ee5\u53ca\u8017\u65f6\uff0c\u901a\u8fc7\u6d4b\u8bd5\u540e\u5f97\u5230\u7684\u7ed3\u679c\u5982\u56fe\u6240\u793a\uff1a \u53ef\u4ee5\u770b\u5230\u4f7f\u7528 for \u5b9e\u73b0\u7684\u51fd\u6570\u8fdc\u8fdc\u4e0d\u5982\u5e7f\u64ad\u673a\u5236\u6765\u7684\u9ad8\u6548\u3002","title":"\u672c\u5730\u6d4b\u8bd5"},{"location":"6Broadcast/#_3","text":"pairwise_similarity def pairwise_similarity ( input_x : torch . Tensor , method : str ) -> torch . Tensor : ''' Calculate similarity matrix with 3 different methods cos, l1, and l2 Input ===== input_x: A Tensor with the shape in [batch_size, feature_size] method: A string indicate the similarity metric method Output ====== similarity_matrix: A Tensor with the shape in [batch_size, batch_size] ''' method_list = ( 'cos' , 'l1' , 'l2' ) if method not in method_list : raise ValueError ( f 'only support method in { method_list } ' ) # TODO: Finish your code here batch_size = input_x . size ( 0 ) similarity_matrix = torch . zeros ( batch_size , batch_size ) if method == 'l1' : similarity_matrix = (( input_x . unsqueeze ( 0 ) - input_x . unsqueeze ( 1 )) . abs ()) . sum ( - 1 ) elif method == 'l2' : similarity_matrix = torch . sqrt ((( input_x . unsqueeze ( 0 ) - input_x . unsqueeze ( 2 )) ** 2 ) . sum ( - 1 )) elif method == 'cos' : similarity_matrix = ( input_x . unsqueeze ( 0 ) * input_x . unsqueeze ( 1 )) / ( input_x . unsqueeze ( 0 ) * input_x . unsqueeze ( 0 )) return similarity_matrix","title":"\u53ef\u80fd\u7684\u7b54\u6848"}]}